{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'google.colab' in str(get_ipython()):\n",
    "    \n",
    "    notebooks = os.path.split(os.getcwd())[0]\n",
    "    root = str(pathlib.Path(notebooks).parent)\n",
    "    sys.path.append(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "\n",
    "import logging\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"  \n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import IPython\n",
    "import IPython.display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "### Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.prototyping.Settings\n",
    "\n",
    "import src.modelling.DataStreams\n",
    "\n",
    "import src.modelling.DataSplitting\n",
    "import src.modelling.DataReconstructions\n",
    "import src.modelling.Differences\n",
    "import src.modelling.DataNormalisation\n",
    "\n",
    "import src.modelling.WindowGenerator\n",
    "import src.modelling.ModellingSteps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Settings:\n",
    "\n",
    "> matplotlib.rcParams.update({'font.size': 13})<br>\n",
    "> matplotlib.rcParams['text.usetex'] = False\n",
    "\n",
    "> plt.rcParams['figure.constrained_layout.use'] = False        \n",
    "\n",
    "> sns.set(font_scale=1)<br>\n",
    "> sns.axes_style('whitegrid', {\"axes.facecolor\": \".9\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.prototyping.Settings.Settings().aesthetics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='\\n%(message)s\\n%(asctime)s.%(msecs)03d\\n',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Data: A Collection of Trusts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### The Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The training, validating, and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fraction = collections.namedtuple(typename='Fraction', field_names=['training', 'validating', 'testing'])\n",
    "training, validating, testing = src.modelling.DataStreams.DataStreams(root=root, fraction=Fraction._make((0.75, 0.15, 0.10))).exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The split shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('training data %s', training.shape)\n",
    "logger.info('validating data %s', validating.shape)\n",
    "logger.info('testing data %s', testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(training.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "### Variable Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "\n",
    "**Reconstructions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions = src.modelling.DataReconstructions.DataReconstructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = reconstructions.exc(blob=training)\n",
    "validating = reconstructions.exc(blob=validating)\n",
    "testing = reconstructions.exc(blob=testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('training data %s', training.shape)\n",
    "logger.info('validating data %s', validating.shape)\n",
    "logger.info('testing data %s', testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(training.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "**Difference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = src.modelling.Differences.Differences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = differences.exc(blob=training)\n",
    "validating = differences.exc(blob=validating)\n",
    "testing = differences.exc(blob=testing)\n",
    "\n",
    "logger.info('training data %s', training.shape)\n",
    "logger.info('validating data %s', validating.shape)\n",
    "logger.info('testing data %s', testing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "**Sample Graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excerpt = training.copy()[['group', 'estimatedNewAdmissions', 'newDeaths28DaysByDeathDate']]\n",
    "excerpt.iloc[:10000, 1:3].plot(subplots = True, ylim=(-100, 100), figsize=(6.5, 5.9));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "**Normalisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Via the means & deviations of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalisation = src.modelling.DataNormalisation.DataNormalisation(reference=training)\n",
    "\n",
    "training_ = normalisation.normalise(blob=training)\n",
    "validating_ = normalisation.normalise(blob=validating)\n",
    "testing_ = normalisation.normalise(blob=testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The normalised values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Training: %s', training_.shape)\n",
    "logger.info('Validating: %s', validating_.shape)\n",
    "logger.info('Testing: %s', testing_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_.drop(columns='point', inplace=True)\n",
    "validating_.drop(columns='point', inplace=True)\n",
    "testing_.drop(columns='point', inplace=True)\n",
    "\n",
    "logger.info(training_.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Case**\n",
    "\n",
    "> * Predict `output_steps` days into the future, based on `input_width` days of history\n",
    "\n",
    "Therefore\n",
    "\n",
    "* $sequence\\_length = total\\_window\\_size = input\\_width + output\\_steps$\n",
    "\n",
    "Noting that\n",
    "\n",
    "* $sequence\\_stride = 1$\n",
    "* $batch\\_size = 32$\n",
    "\n",
    "**always**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Hence, **defining a *modelling arguments* class** for declaring a set of model arguments, including windowing arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arguments = collections.namedtuple(typename='Arguments', \n",
    "                                   field_names=['input_width', 'label_width', 'shift', 'training_', 'validating_', 'testing_', 'label_columns'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Initialising a *modelling arguments* class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = range(27, 40)\n",
    "output_steps = 15\n",
    "input_width = widths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = Arguments(input_width=input_width, label_width=output_steps, shift=output_steps, \n",
    "                      training_=training_, validating_=validating_, testing_=testing_, \n",
    "                      label_columns=['estimatedNewAdmissions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Initialising a modelling window generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = src.modelling.WindowGenerator.WindowGenerator(\n",
    "    input_width=arguments.input_width, label_width=arguments.label_width, shift=arguments.shift,\n",
    "    training=arguments.training_, validating=arguments.validating_, testing=arguments.testing_, \n",
    "    label_columns=arguments.label_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Specifications**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(window.train.element_spec)\n",
    "logger.info(window.validate.element_spec)\n",
    "logger.info(window.test.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = training_.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Initiate a generic modelling steps instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = src.modelling.ModellingSteps.ModellingSteps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validations = pd.DataFrame(columns=['method', 'history', 'ahead', 'loss', 'mae'])\n",
    "tests = pd.DataFrame(columns=['method', 'history', 'ahead', 'loss', 'mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "### Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_width = input_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution = tf.keras.Sequential([    \n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -convolution_width:, :]),    \n",
    "    tf.keras.layers.Conv1D(256, activation='relu', kernel_size=(convolution_width)),\n",
    "    tf.keras.layers.Dense(output_steps * n_features, kernel_initializer=tf.initializers.zeros()),\n",
    "    tf.keras.layers.Reshape([output_steps, n_features])\n",
    "])\n",
    "\n",
    "convolution_ = steps.modelling(model=convolution, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validations.loc[validations.shape[0], :] = ['CNN', input_width, output_steps] + convolution_.model.evaluate(window.validate, verbose=0)\n",
    "tests.loc[tests.shape[0], :] = ['CNN', input_width, output_steps] + convolution_.model.evaluate(window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = tf.keras.Sequential([    \n",
    "    tf.keras.layers.LSTM(32, return_sequences=False),    \n",
    "    tf.keras.layers.Dense(output_steps * n_features, kernel_initializer=tf.initializers.zeros()),    \n",
    "    tf.keras.layers.Reshape([output_steps, n_features])\n",
    "])\n",
    "\n",
    "lstm_ = steps.modelling(model=lstm, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validations.loc[validations.shape[0], :] = ['LSTM', input_width, output_steps] + lstm_.model.evaluate(window.validate, verbose=0)\n",
    "tests.loc[tests.shape[0], :] = ['LSTM', input_width, output_steps] + lstm_.model.evaluate(window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "### GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "gru = tf.keras.Sequential([\n",
    "    tf.keras.layers.GRU(32, input_shape=(input_width, n_features), return_sequences=True, activation='relu', kernel_initializer=tf.initializers.HeUniform()),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.GRU(16, return_sequences=True, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.GRU(output_steps * n_features, activation='relu'),\n",
    "    tf.keras.layers.Reshape([output_steps, n_features])\n",
    "])\n",
    "\n",
    "gru_ = steps.modelling(model=gru, window=window)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "validations.loc[validations.shape[0], :] = ['GRU', input_width, output_steps] + gru_.model.evaluate(window.validate, verbose=0)\n",
    "tests.loc[tests.shape[0], :] = ['GRU', input_width, output_steps] + gru_.model.evaluate(window.test, verbose=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Histories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolution_history = pd.DataFrame(convolution_.history)\n",
    "convolution_history.loc[:, 'method'] = 'CNN'\n",
    "convolution_history.loc[:, 'history'] = input_width\n",
    "convolution_history.loc[:, 'ahead'] = output_steps\n",
    "convolution_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_history = pd.DataFrame(data=lstm_.history)\n",
    "lstm_history.loc[:, 'method'] = 'LSTM'\n",
    "lstm_history.loc[:, 'history'] = input_width\n",
    "lstm_history.loc[:, 'ahead'] = output_steps\n",
    "lstm_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**GRU**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "gru_history = pd.DataFrame(data=gru_.history)\n",
    "gru_history.loc[:, 'method'] = 'GRU'\n",
    "gru_history.loc[:, 'history'] = input_width\n",
    "gru_history.loc[:, 'ahead'] = output_steps\n",
    "gru_history\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
