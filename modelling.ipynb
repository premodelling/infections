{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is focused on the modelling aspect of the project.  It predominantly depends on the modules of [src/modelling](./src/modelling), and on the raw design matrix data [warehouse/design/raw](./warehouse/design/raw). &nbsp;&nbsp; The developed models depend on TensorFlow, and their program's\n",
    "\n",
    "* [Convolutional Neural Network](./src/modelling/EstimatesCNN.py)\n",
    "* [Long short-term memory (LSTM)](./src/modelling/EstimatesLSTM.py)\n",
    "* [Gated Recurrent Unit (GRU)](./src/modelling/EstimatesGRU.py)\n",
    "\n",
    "are GPU (graphics processing units) compatible. &nbsp;&nbsp; In order to run the programs within a GPU enabled machine disable the text \n",
    "\n",
    "> os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "within each of the three model files. &nbsp;&nbsp; This text enables a CPU (Central Processing Unit) based run; the programs are GPU programs by default. \n",
    "\n",
    "<br>\n",
    "\n",
    "The [project report](https://github.com/premodelling/trusts/blob/master/trusts.pdf) includes a summary of the error metrics w.r.t. the developed models.  Additionally, an [online graphical summary](https://public.tableau.com/app/profile/greyhypotheses/viz/SCC460Project/SCC460) of the error metrics, w.r.t. a few runs of the developed models, is available [here](https://public.tableau.com/app/profile/greyhypotheses/viz/SCC460Project/SCC460).  In general, the error metrics due to model runs are stored in [warehouse/modelling/evaluations/](./warehouse/modelling/evaluations)\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'google.colab' in str(get_ipython()):\n",
    "    \n",
    "    parts = pathlib.Path(os.getcwd()).parts    \n",
    "    limit = max([index for index, value in enumerate(parts) if value == 'infections'])    \n",
    "    parent = os.path.join(*list(parts[:(limit + 1)]))\n",
    "    \n",
    "    sys.path.append(os.path.join(parent, 'src'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'J:\\\\library\\\\premodelling\\\\projects\\\\infections'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "\n",
    "import logging\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.modelling.DataStreams\n",
    "import src.modelling.DataReconstructions\n",
    "import src.modelling.Differences\n",
    "import src.modelling.DataNormalisation\n",
    "import src.modelling.Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='\\n\\n%(message)s\\n%(asctime)s.%(msecs)03d',\n",
    "                        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "## Part II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A class for the data splitting fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fraction = collections.namedtuple(\n",
    "    typename='Fraction',\n",
    "    field_names=['training', 'validating', 'testing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Modelling Arguments**\n",
    "\n",
    "> * Predict `output_steps` days into the future, based on `input_width` days of history\n",
    "\n",
    "Herein\n",
    "\n",
    "* $input\\_width \\in widths$  $\\qquad$  [$widths$ is a range of input window values (days)]\n",
    "* $output\\_steps = 15$ days\n",
    "  \n",
    "And\n",
    "\n",
    "* $label\\_width = output\\_steps$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Arguments = collections.namedtuple(\n",
    "    typename='Arguments',\n",
    "    field_names=['input_width', 'label_width', 'shift', 'training_', 'validating_', 'testing_', 'label_columns'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Vary the widths' range as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = range(18, 39)\n",
    "output_steps = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "### Training, Validating, Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foremost: The data sets for training, validating, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validating, testing = src.modelling.DataStreams.DataStreams(root=parent, fraction=Fraction._make(\n",
    "        (0.75, 0.15, 0.10))).exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Index(['group', 'date', 'covidOccupiedBeds', 'covidOccupiedMVBeds',\n",
      "       'estimatedNewAdmissions', 'EDC0-4', 'EDC5-9', 'EDC10-14', 'EDC15-19',\n",
      "       'EDC20-24', 'EDC25-29', 'EDC30-34', 'EDC35-39', 'EDC40-44', 'EDC45-49',\n",
      "       'EDC50-54', 'EDC55-59', 'EDC60-64', 'EDC65-69', 'EDC70-74', 'EDC75-79',\n",
      "       'EDC80-84', 'EDC85-89', 'EDC90+', 'newDeaths28DaysByDeathDate',\n",
      "       'EDV12-15', 'EDV16-17', 'EDV18-24', 'EDV25-29', 'EDV30-34', 'EDV35-39',\n",
      "       'EDV40-44', 'EDV45-49', 'EDV50-54', 'EDV55-59', 'EDV60-64', 'EDV65-69',\n",
      "       'EDV70-74', 'EDV75-79', 'EDV80-84', 'EDV85-89', 'EDV90+'],\n",
      "      dtype='object')\n",
      "2022-03-30 15:48:53.101\n"
     ]
    }
   ],
   "source": [
    "logger.info(training.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "### Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstructions: Each data set is a concatenation of records from various NHS Trusts, however because the aim is a single predicting/forecasting model for all trusts, the data should be reconstructed ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions = src.modelling.DataReconstructions.DataReconstructions()\n",
    "training = reconstructions.exc(blob=training)\n",
    "validating = reconstructions.exc(blob=validating)\n",
    "testing = reconstructions.exc(blob=testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "### Differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using difference values rather than actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = src.modelling.Differences.Differences()\n",
    "training = differences.exc(blob=training)\n",
    "validating = differences.exc(blob=validating)\n",
    "testing = differences.exc(blob=testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "### Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalisation = src.modelling.DataNormalisation.DataNormalisation(reference=training)\n",
    "training_ = normalisation.normalise(blob=training)\n",
    "validating_ = normalisation.normalise(blob=validating)\n",
    "testing_ = normalisation.normalise(blob=testing)\n",
    "\n",
    "training_.drop(columns='point', inplace=True)\n",
    "validating_.drop(columns='point', inplace=True)\n",
    "testing_.drop(columns='point', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting error metrics are stored in [warehouse/modelling/evaluations/](./warehouse/modelling/evaluations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = Arguments(input_width=None, label_width=output_steps, shift=output_steps,\n",
    "                      training_=training_, validating_=validating_, testing_=testing_,\n",
    "                      label_columns=['estimatedNewAdmissions'])\n",
    "\n",
    "validations, tests = src.modelling.Estimates.Estimates(\n",
    "    n_features=training_.shape[1], \n",
    "    output_steps=output_steps).exc(widths=widths, arguments=arguments)\n",
    "\n",
    "logger.info(validations)\n",
    "logger.info(tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "### Delete DAG Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "rm -rf *.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
